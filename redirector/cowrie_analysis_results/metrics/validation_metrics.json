{
  "HonestyHumility": {
    "auc": 0.8484279918864097,
    "f1_best": 0.8221574344023324,
    "best_threshold": 0.12000000000000001,
    "f1_default": 0.4021164021164021,
    "samples": 281
  },
  "Emotionality": {
    "auc": 0.8273326572008114,
    "f1_best": 0.7701863354037267,
    "best_threshold": 0.13,
    "f1_default": 0.5133689839572193,
    "samples": 252
  },
  "Extraversion": {
    "auc": 0.8763923013923014,
    "f1_best": 0.8053691275167785,
    "best_threshold": 0.19,
    "f1_default": 0.4878048780487805,
    "samples": 313
  },
  "Agreeableness": {
    "auc": 0.8241592772293792,
    "f1_best": 0.7558528428093646,
    "best_threshold": 0.16,
    "f1_default": 0.3803680981595092,
    "samples": 268
  },
  "Conscientiousness": {
    "auc": 0.868630201028518,
    "f1_best": 0.8308605341246291,
    "best_threshold": 0.16,
    "f1_default": 0.5135135135135135,
    "samples": 293
  },
  "OpennessToExperience": {
    "auc": 0.8564471057884232,
    "f1_best": 0.8072916666666666,
    "best_threshold": 0.15000000000000002,
    "f1_default": 0.4484304932735426,
    "samples": 317
  },
  "cv": {
    "HonestyHumility": {
      "samples": 281,
      "auc_oof": 0.7456135902636916,
      "auc_oof_ci95": [
        0.6920450241791156,
        0.8019534960840716
      ],
      "f1_oof@0.5": 0.31693989071038253,
      "f1_oof@cv_thr": 0.7580645161290323,
      "f1_oof@cv_thr_ci95": [
        0.7033747914454725,
        0.7995039164490861
      ],
      "best_threshold_cv_mean": 0.11,
      "brier": 0.27441977222591457,
      "ece": 0.2538026931435792
    },
    "Emotionality": {
      "samples": 252,
      "auc_oof": 0.6891797667342799,
      "auc_oof_ci95": [
        0.6276581294989716,
        0.7493258086662778
      ],
      "f1_oof@0.5": 0.45555555555555555,
      "f1_oof@cv_thr": 0.7065868263473054,
      "f1_oof@cv_thr_ci95": [
        0.6495841697734442,
        0.7608251277576966
      ],
      "best_threshold_cv_mean": 0.11,
      "brier": 0.29017584968283944,
      "ece": 0.2766630328535165
    },
    "Extraversion": {
      "samples": 313,
      "auc_oof": 0.77010647010647,
      "auc_oof_ci95": [
        0.7190897294127632,
        0.8188979116071401
      ],
      "f1_oof@0.5": 0.4321608040201005,
      "f1_oof@cv_thr": 0.7065527065527065,
      "f1_oof@cv_thr_ci95": [
        0.6476569526893327,
        0.7600674084676116
      ],
      "best_threshold_cv_mean": 0.12000000000000001,
      "brier": 0.2536567772448908,
      "ece": 0.23830209973467575
    },
    "Agreeableness": {
      "samples": 268,
      "auc_oof": 0.643745468741286,
      "auc_oof_ci95": [
        0.5728282481691409,
        0.7044666314588189
      ],
      "f1_oof@0.5": 0.267515923566879,
      "f1_oof@cv_thr": 0.6459627329192547,
      "f1_oof@cv_thr_ci95": [
        0.5893515060990789,
        0.7037607255349191
      ],
      "best_threshold_cv_mean": 0.11,
      "brier": 0.295078869003297,
      "ece": 0.25593219933569583
    },
    "Conscientiousness": {
      "samples": 293,
      "auc_oof": 0.7652641421224872,
      "auc_oof_ci95": [
        0.700994617598511,
        0.8133987359037629
      ],
      "f1_oof@0.5": 0.4537037037037037,
      "f1_oof@cv_thr": 0.7684210526315789,
      "f1_oof@cv_thr_ci95": [
        0.7173479228486647,
        0.8143457674247789
      ],
      "best_threshold_cv_mean": 0.1,
      "brier": 0.2663582737014111,
      "ece": 0.24922291297819213
    },
    "OpennessToExperience": {
      "samples": 317,
      "auc_oof": 0.7458682634730539,
      "auc_oof_ci95": [
        0.6888038161452634,
        0.7978931843617061
      ],
      "f1_oof@0.5": 0.34418604651162793,
      "f1_oof@cv_thr": 0.7475728155339806,
      "f1_oof@cv_thr_ci95": [
        0.7011292849772615,
        0.7945977633477632
      ],
      "best_threshold_cv_mean": 0.11,
      "brier": 0.2685871855420798,
      "ece": 0.24627700893168256
    }
  }
}